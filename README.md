# ğŸ§  Project Optics â€“ Real-Time ASL Recognition Model ğŸ¤Ÿ by ThunderGuyk, and ProGamerTejaji, and Shyam and other friends lmao

**Project Optics** is a deep learning-powered application that recognizes American Sign Language (ASL) gestures in real-time using your webcam. Trained on a custom dataset and engineered with love, math, and way too many `.pt` files, this model bridges silence with speech using the language of light and code.

> â€œWhere words fail, fingers speak.â€

---

## ğŸš€ Features

- ğŸ”® **Live Prediction:** Captures and interprets ASL signs in real time using your webcam.
- ğŸ¯ **Custom Trained Model:** Leveraging PyTorch for efficient and accurate gesture recognition.
- ğŸ§° **Modular Code:** Easy to understand, extend, and customize.
- âš¡ **Fast & Responsive:** Optimized inference for low latency predictions.
- ğŸ‘ï¸ **Visualization:** Optional bounding box, label display, and performance stats overlay.

---

## ğŸ› ï¸ How It Works

1. **Data Collection:** ASL images/videos were gathered, labeled, and preprocessed.
2. **Model Training:** A CNN (or your architecture of choice) was trained using PyTorch.
3. **Live Inference:** OpenCV captures live feed, and the trained model predicts each frame's sign.

---

## ğŸ“¦ Installation

Clone this repo:

```bash
git clone https://github.com/your-username/project-optics.git
cd project-optics
